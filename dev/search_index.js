var documenterSearchIndex = {"docs":
[{"location":"dataset/#Dataset","page":"Dataset","title":"Dataset","text":"","category":"section"},{"location":"dataset/","page":"Dataset","title":"Dataset","text":"Pages = [\"dataset.md\"]","category":"page"},{"location":"dataset/#Type-definition","page":"Dataset","title":"Type definition","text":"","category":"section"},{"location":"dataset/#InferenceObjects.Dataset","page":"Dataset","title":"InferenceObjects.Dataset","text":"Dataset{K,T,N,L} <: DimensionalData.AbstractDimStack{K,T,N,L}\n\nContainer of dimensional arrays sharing some dimensions.\n\nThis type is an DimensionalData.AbstractDimStack that implements the same interface as DimensionalData.DimStack and has identical usage.\n\nConstructors\n\nDataset(data::DimensionalData.AbstractDimArray...)\nDataset(data::Tuple{Vararg{<:DimensionalData.AbstractDimArray}})\nDataset(data::NamedTuple{Keys,Vararg{<:DimensionalData.AbstractDimArray}})\nDataset(\n    data::NamedTuple,\n    dims::Tuple{Vararg{DimensionalData.Dimension}};\n    metadata=DimensionalData.NoMetadata(),\n)\n\nIn most cases, use convert_to_dataset to create a Dataset instead of directly using a constructor.\n\n\n\n\n\n","category":"type"},{"location":"dataset/#General-conversion","page":"Dataset","title":"General conversion","text":"","category":"section"},{"location":"dataset/#InferenceObjects.convert_to_dataset","page":"Dataset","title":"InferenceObjects.convert_to_dataset","text":"convert_to_dataset(obj; group = :posterior, kwargs...) -> Dataset\n\nConvert a supported object to a Dataset.\n\nIn most cases, this function calls convert_to_inference_data and returns the corresponding group.\n\n\n\n\n\n","category":"function"},{"location":"dataset/#InferenceObjects.namedtuple_to_dataset","page":"Dataset","title":"InferenceObjects.namedtuple_to_dataset","text":"namedtuple_to_dataset(data; kwargs...) -> Dataset\n\nConvert NamedTuple mapping variable names to arrays to a Dataset.\n\nAny non-array values will be converted to a 0-dimensional array.\n\nKeywords\n\nattrs::AbstractDict{<:AbstractString}: a collection of metadata to attach to the dataset, in addition to defaults. Values should be JSON serializable.\nlibrary::Union{String,Module}: library used for performing inference. Will be attached to the attrs metadata.\ndims: a collection mapping variable names to collections of objects containing dimension names. Acceptable such objects are:\nSymbol: dimension name\nType{<:DimensionsionalData.Dimension}: dimension type\nDimensionsionalData.Dimension: dimension, potentially with indices\nNothing: no dimension name provided, dimension name is automatically generated\ncoords: a collection indexable by dimension name specifying the indices of the given dimension. If indices for a dimension in dims are provided, they are used even if the dimension contains its own indices. If a dimension is missing, its indices are automatically generated.\n\n\n\n\n\n","category":"function"},{"location":"dataset/#DimensionalData","page":"Dataset","title":"DimensionalData","text":"","category":"section"},{"location":"dataset/","page":"Dataset","title":"Dataset","text":"As a DimensionalData.AbstractDimStack, Dataset also implements the AbstractDimStack API and can be used like a DimStack. See DimensionalData's documentation for example usage.","category":"page"},{"location":"dataset/#Tables-inteface","page":"Dataset","title":"Tables inteface","text":"","category":"section"},{"location":"dataset/","page":"Dataset","title":"Dataset","text":"Dataset implements the Tables interface. This allows Datasets to be used as sources for any function that can accept a table. For example, it's straightforward to:","category":"page"},{"location":"dataset/","page":"Dataset","title":"Dataset","text":"write to CSV with CSV.jl\nflatten to a DataFrame with DataFrames.jl\nplot with StatsPlots.jl\nplot with AlgebraOfGraphics.jl","category":"page"},{"location":"extensions/mcmcdiagnostictools/#Extension-of-MCMCDiagnosticTools","page":"MCMCDiagnosticTools","title":"Extension of MCMCDiagnosticTools","text":"","category":"section"},{"location":"extensions/mcmcdiagnostictools/","page":"MCMCDiagnosticTools","title":"MCMCDiagnosticTools","text":"The following methods of MCMCDiagnosticTools.jl are extended by this package.","category":"page"},{"location":"extensions/mcmcdiagnostictools/","page":"MCMCDiagnosticTools","title":"MCMCDiagnosticTools","text":"Modules = [MCMCDiagnosticTools]","category":"page"},{"location":"extensions/mcmcdiagnostictools/#MCMCDiagnosticTools.bfmi-Tuple{InferenceData}","page":"MCMCDiagnosticTools","title":"MCMCDiagnosticTools.bfmi","text":"bfmi(data::InferenceData) -> DimArray\nbfmi(sample_stats::Dataset) -> DimArray\n\nCalculate the chainwise estimated Bayesian fraction of missing information (BFMI).\n\nSee MCMCDiagnosticTools.bfmi for more details.\n\n\n\n\n\n","category":"method"},{"location":"extensions/mcmcdiagnostictools/#MCMCDiagnosticTools.ess_rhat-Tuple{InferenceData}","page":"MCMCDiagnosticTools","title":"MCMCDiagnosticTools.ess_rhat","text":"ess_rhat(data::InferenceData; kwargs...) -> Dataset\ness_rhat(data::Dataset; kwargs...) -> Dataset\n\nCalculate the effective sample size (ESS) and widehatR diagnostic for each parameter in the data.\n\nFor more details and a description of the kwargs, see MCMCDiagnosticTools.ess_rhat.\n\n\n\n\n\n","category":"method"},{"location":"extensions/mcmcdiagnostictools/#MCMCDiagnosticTools.mcse-Tuple{InferenceData}","page":"MCMCDiagnosticTools","title":"MCMCDiagnosticTools.mcse","text":"mcse(data::InferenceData; kwargs...) -> Dataset\nmcse(data::Dataset; kwargs...) -> Dataset\n\nCalculate the Monte Carlo standard error (MCSE) for each parameter in the data.\n\nFor more details and a description of the kwargs, see MCMCDiagnosticTools.mcse.\n\n\n\n\n\n","category":"method"},{"location":"extensions/mcmcdiagnostictools/#MCMCDiagnosticTools.rstar-Tuple{Random.AbstractRNG, Any, InferenceData}","page":"MCMCDiagnosticTools","title":"MCMCDiagnosticTools.rstar","text":"rstar(\n    rng::Random.AbstractRNG=Random.default_rng(),\n    classifier,\n    data::Union{InferenceData,Dataset};\n    kwargs...,\n)\n\nCalculate the R^* diagnostic for the data.\n\nFor a description of the classifier and kwargs, see MCMCDiagnosticTools.rstar.\n\n\n\n\n\n","category":"method"},{"location":"inference_data/#InferenceData","page":"InferenceData","title":"InferenceData","text":"","category":"section"},{"location":"inference_data/","page":"InferenceData","title":"InferenceData","text":"Pages = [\"inference_data.md\"]","category":"page"},{"location":"inference_data/#Type-definition","page":"InferenceData","title":"Type definition","text":"","category":"section"},{"location":"inference_data/#InferenceObjects.InferenceData","page":"InferenceData","title":"InferenceObjects.InferenceData","text":"InferenceData{group_names,group_types}\n\nContainer for inference data storage using DimensionalData.\n\nThis object implements the InferenceData schema.\n\nInternally, groups are stored in a NamedTuple, which can be accessed using parent(::InferenceData).\n\nConstructors\n\nInferenceData(groups::NamedTuple)\nInferenceData(; groups...)\n\nConstruct an inference data from either a NamedTuple or keyword arguments of groups.\n\nGroups must be Dataset objects.\n\nInstead of directly creating an InferenceData, use the exported from_xyz functions or convert_to_inference_data.\n\n\n\n\n\n","category":"type"},{"location":"inference_data/#Property-interface","page":"InferenceData","title":"Property interface","text":"","category":"section"},{"location":"inference_data/#Base.getproperty","page":"InferenceData","title":"Base.getproperty","text":"getproperty(data::InferenceData, name::Symbol) -> Dataset\n\nGet group with the specified name.\n\n\n\n\n\n","category":"function"},{"location":"inference_data/#Base.propertynames","page":"InferenceData","title":"Base.propertynames","text":"propertynames(data::InferenceData) -> Tuple{Symbol}\n\nGet names of groups\n\n\n\n\n\n","category":"function"},{"location":"inference_data/#Indexing-interface","page":"InferenceData","title":"Indexing interface","text":"","category":"section"},{"location":"inference_data/#Base.getindex","page":"InferenceData","title":"Base.getindex","text":"Base.getindex(data::InferenceData, groups::Symbol; coords...) -> Dataset\nBase.getindex(data::InferenceData, groups; coords...) -> InferenceData\n\nReturn a new InferenceData containing the specified groups sliced to the specified coords.\n\ncoords specifies a dimension name mapping to an index, a DimensionalData.Selector, or an IntervalSets.AbstractInterval.\n\nIf one or more groups lack the specified dimension, a warning is raised but can be ignored. All groups that contain the dimension must also contain the specified indices, or an exception will be raised.\n\nExamples\n\nSelect data from all groups for just the specified id values.\n\njulia> using InferenceObjects, DimensionalData\n\njulia> idata = from_namedtuple(\n           (θ=randn(4, 100, 4), τ=randn(4, 100));\n           prior=(θ=randn(4, 100, 4), τ=randn(4, 100)),\n           observed_data=(y=randn(4),),\n           dims=(θ=[:id], y=[:id]),\n           coords=(id=[\"a\", \"b\", \"c\", \"d\"],),\n       )\nInferenceData with groups:\n  > posterior\n  > prior\n  > observed_data\n\njulia> idata.posterior\nDataset with dimensions:\n  Dim{:chain} Sampled 1:4 ForwardOrdered Regular Points,\n  Dim{:draw} Sampled 1:100 ForwardOrdered Regular Points,\n  Dim{:id} Categorical String[a, b, c, d] ForwardOrdered\nand 2 layers:\n  :θ Float64 dims: Dim{:chain}, Dim{:draw}, Dim{:id} (4×100×4)\n  :τ Float64 dims: Dim{:chain}, Dim{:draw} (4×100)\n\nwith metadata Dict{String, Any} with 1 entry:\n  \"created_at\" => \"2022-08-11T11:15:21.4\"\n\njulia> idata_sel = idata[id=At([\"a\", \"b\"])]\nInferenceData with groups:\n  > posterior\n  > prior\n  > observed_data\n\njulia> idata_sel.posterior\nDataset with dimensions:\n  Dim{:chain} Sampled 1:4 ForwardOrdered Regular Points,\n  Dim{:draw} Sampled 1:100 ForwardOrdered Regular Points,\n  Dim{:id} Categorical String[a, b] ForwardOrdered\nand 2 layers:\n  :θ Float64 dims: Dim{:chain}, Dim{:draw}, Dim{:id} (4×100×2)\n  :τ Float64 dims: Dim{:chain}, Dim{:draw} (4×100)\n\nwith metadata Dict{String, Any} with 1 entry:\n  \"created_at\" => \"2022-08-11T11:15:21.4\"\n\nSelect data from just the posterior, returning a Dataset if the indices index more than one element from any of the variables:\n\njulia> idata[:observed_data, id=At([\"a\"])]\nDataset with dimensions:\n  Dim{:id} Categorical String[a] ForwardOrdered\nand 1 layer:\n  :y Float64 dims: Dim{:id} (1)\n\nwith metadata Dict{String, Any} with 1 entry:\n  \"created_at\" => \"2022-08-11T11:19:25.982\"\n\nNote that if a single index is provided, the behavior is still to slice so that the dimension is preserved.\n\n\n\n\n\n","category":"function"},{"location":"inference_data/#Base.setindex","page":"InferenceData","title":"Base.setindex","text":"Base.setindex(data::InferenceData, group::Dataset, name::Symbol) -> InferenceData\n\nCreate a new InferenceData containing the group with the specified name.\n\nIf a group with name is already in data, it is replaced.\n\n\n\n\n\n","category":"function"},{"location":"inference_data/#Iteration-interface","page":"InferenceData","title":"Iteration interface","text":"","category":"section"},{"location":"inference_data/","page":"InferenceData","title":"InferenceData","text":"InferenceData also implements the same iteration interface as its underlying NamedTuple. That is, iterating over an InferenceData iterates over its groups.","category":"page"},{"location":"inference_data/#General-conversion","page":"InferenceData","title":"General conversion","text":"","category":"section"},{"location":"inference_data/#InferenceObjects.convert_to_inference_data","page":"InferenceData","title":"InferenceObjects.convert_to_inference_data","text":"convert_to_inference_data(obj; group, kwargs...) -> InferenceData\n\nConvert a supported object to an InferenceData object.\n\nIf obj converts to a single dataset, group specifies which dataset in the resulting InferenceData that is.\n\nSee convert_to_dataset\n\nArguments\n\nobj can be many objects. Basic supported types are:\nInferenceData: return unchanged\nDataset/DimensionalData.AbstractDimStack: add to InferenceData as the only group\nNamedTuple/AbstractDict: create a Dataset as the only group\nAbstractArray{<:Real}: create a Dataset as the only group, given an arbitrary name, if the name is not set\n\nMore specific types may be documented separately.\n\nKeywords\n\ngroup::Symbol = :posterior: If obj converts to a single dataset, assign the resulting dataset to this group.\ndims: a collection mapping variable names to collections of objects containing dimension names. Acceptable such objects are:\nSymbol: dimension name\nType{<:DimensionsionalData.Dimension}: dimension type\nDimensionsionalData.Dimension: dimension, potentially with indices\nNothing: no dimension name provided, dimension name is automatically generated\ncoords: a collection indexable by dimension name specifying the indices of the given dimension. If indices for a dimension in dims are provided, they are used even if the dimension contains its own indices. If a dimension is missing, its indices are automatically generated.\nkwargs: remaining keywords forwarded to converter functions\n\n\n\n\n\n","category":"function"},{"location":"inference_data/#InferenceObjects.from_dict","page":"InferenceData","title":"InferenceObjects.from_dict","text":"from_dict(posterior::AbstractDict; kwargs...) -> InferenceData\n\nConvert a dictionary to an InferenceData.\n\nArguments\n\nposterior: The data to be converted. Its strings must be Symbol or AbstractString, and its values must be arrays.\n\nKeywords\n\nposterior_predictive::Any=nothing: Draws from the posterior predictive distribution\nsample_stats::Any=nothing: Statistics of the posterior sampling process\npredictions::Any=nothing: Out-of-sample predictions for the posterior.\nprior::Dict=nothing: Draws from the prior\nprior_predictive::Any=nothing: Draws from the prior predictive distribution\nsample_stats_prior::Any=nothing: Statistics of the prior sampling process\nobserved_data::NamedTuple: Observed data on which the posterior is conditional. It should only contain data which is modeled as a random variable. Keys are parameter names and values.\nconstant_data::NamedTuple: Model constants, data included in the model which is not modeled as a random variable. Keys are parameter names and values.\npredictions_constant_data::NamedTuple: Constants relevant to the model predictions (i.e. new x values in a linear regression).\nlog_likelihood: Pointwise log-likelihood for the data. It is recommended to use this argument as a NamedTuple whose keys are observed variable names and whose values are log likelihood arrays.\nlibrary: Name of library that generated the draws\ncoords: Map from named dimension to named indices\ndims: Map from variable name to names of its dimensions\n\nReturns\n\nInferenceData: The data with groups corresponding to the provided data\n\nExamples\n\nusing InferenceObjects\nnchains = 2\nndraws = 100\n\ndata = Dict(\n    :x => rand(ndraws, nchains),\n    :y => randn(2, ndraws, nchains),\n    :z => randn(3, 2, ndraws, nchains),\n)\nidata = from_dict(data)\n\n\n\n\n\n","category":"function"},{"location":"inference_data/#InferenceObjects.from_namedtuple","page":"InferenceData","title":"InferenceObjects.from_namedtuple","text":"from_namedtuple(posterior::NamedTuple; kwargs...) -> InferenceData\nfrom_namedtuple(posterior::Vector{Vector{<:NamedTuple}}; kwargs...) -> InferenceData\nfrom_namedtuple(\n    posterior::NamedTuple,\n    sample_stats::Any,\n    posterior_predictive::Any,\n    predictions::Any,\n    log_likelihood::Any;\n    kwargs...\n) -> InferenceData\n\nConvert a NamedTuple or container of NamedTuples to an InferenceData.\n\nIf containers are passed, they are flattened into a single NamedTuple with array elements whose first dimensions correspond to the dimensions of the containers.\n\nArguments\n\nposterior: The data to be converted. It may be of the following types:\n::NamedTuple: The keys are the variable names and the values are arrays with dimensions (ndraws, nchains[, sizes...]).\n::Vector{Vector{<:NamedTuple}}: A vector of length nchains whose elements have length ndraws.\n\nKeywords\n\nposterior_predictive::Any=nothing: Draws from the posterior predictive distribution\nsample_stats::Any=nothing: Statistics of the posterior sampling process\npredictions::Any=nothing: Out-of-sample predictions for the posterior.\nprior=nothing: Draws from the prior. Accepts the same types as posterior.\nprior_predictive::Any=nothing: Draws from the prior predictive distribution\nsample_stats_prior::Any=nothing: Statistics of the prior sampling process\nobserved_data::NamedTuple: Observed data on which the posterior is conditional. It should only contain data which is modeled as a random variable. Keys are parameter names and values.\nconstant_data::NamedTuple: Model constants, data included in the model which is not modeled as a random variable. Keys are parameter names and values.\npredictions_constant_data::NamedTuple: Constants relevant to the model predictions (i.e. new x values in a linear regression).\nlog_likelihood: Pointwise log-likelihood for the data. It is recommended to use this argument as a NamedTuple whose keys are observed variable names and whose values are log likelihood arrays.\nlibrary: Name of library that generated the draws\ncoords: Map from named dimension to named indices\ndims: Map from variable name to names of its dimensions\n\nReturns\n\nInferenceData: The data with groups corresponding to the provided data\n\nnote: Note\nIf a NamedTuple is provided for observed_data, constant_data, or predictionsconstantdata`, any non-array values (e.g. integers) are converted to 0-dimensional arrays.\n\nExamples\n\nusing InferenceObjects\nnchains = 2\nndraws = 100\n\ndata1 = (\n    x=rand(ndraws, nchains), y=randn(ndraws, nchains, 2), z=randn(ndraws, nchains, 3, 2)\n)\nidata1 = from_namedtuple(data1)\n\ndata2 = [[(x=rand(), y=randn(2), z=randn(3, 2)) for _ in 1:ndraws] for _ in 1:nchains];\nidata2 = from_namedtuple(data2)\n\n\n\n\n\n","category":"function"},{"location":"inference_data/#General-functions","page":"InferenceData","title":"General functions","text":"","category":"section"},{"location":"inference_data/#Base.cat","page":"InferenceData","title":"Base.cat","text":"cat(data::InferenceData...; [groups=keys(data[1]),] dims) -> InferenceData\n\nConcatenate InferenceData objects along the specified dimension dims.\n\nOnly the groups in groups are concatenated. Remaining groups are merged into the new InferenceData object.\n\nExamples\n\nHere is how we can concatenate all groups of two InferenceData objects along the existing chain dimension:\n\njulia> coords = (; a_dim=[\"x\", \"y\", \"z\"]);\n\njulia> dims = dims=(; a=[:a_dim]);\n\njulia> data = Dict(:a => randn(100, 4, 3), :b => randn(100, 4));\n\njulia> idata = from_dict(data; coords=coords, dims=dims)\nInferenceData with groups:\n  > posterior\n\njulia> idata_cat1 = cat(idata, idata; dims=:chain)\nInferenceData with groups:\n  > posterior\n\njulia> idata_cat1.posterior\n┌ 100×8×3 Dataset ┐\n├─────────────────┴──────────────────────────────────── dims ┐\n  ↓ draw,\n  → chain,\n  ↗ a_dim Categorical{String} [\"x\", …, \"z\"] ForwardOrdered\n├──────────────────────────────────────────────────── layers ┤\n  :a eltype: Float64 dims: draw, chain, a_dim size: 100×8×3\n  :b eltype: Float64 dims: draw, chain size: 100×8\n├────────────────────────────────────────────────── metadata ┤\n  Dict{String, Any} with 1 entry:\n  \"created_at\" => \"2025-07-25T10:11:18.92\"\n\nAlternatively, we can concatenate along a new run dimension, which will be created.\n\njulia> idata_cat2 = cat(idata, idata; dims=:run)\nInferenceData with groups:\n  > posterior\n\njulia> idata_cat2.posterior\n┌ 100×4×3×2 Dataset ┐\n├───────────────────┴───────────────────────────────────────── dims ┐\n  ↓ draw,\n  → chain,\n  ↗ a_dim Categorical{String} [\"x\", …, \"z\"] ForwardOrdered,\n  ⬔ run\n├─────────────────────────────────────────────────────────── layers ┤\n  :a eltype: Float64 dims: draw, chain, a_dim, run size: 100×4×3×2\n  :b eltype: Float64 dims: draw, chain, run size: 100×4×2\n├───────────────────────────────────────────────────────── metadata ┤\n  Dict{String, Any} with 1 entry:\n  \"created_at\" => \"2025-07-25T10:11:18.92\"\n\nWe can also concatenate only a subset of groups and merge the rest, which is useful when some groups are present only in some of the InferenceData objects or will be identical in all of them:\n\njulia> observed_data = Dict(:y => randn(10));\n\njulia> idata2 = from_dict(data; observed_data=observed_data, coords=coords, dims=dims)\nInferenceData with groups:\n  > posterior\n  > observed_data\n\njulia> idata_cat3 = cat(idata, idata2; groups=(:posterior,), dims=:run)\nInferenceData with groups:\n  > posterior\n  > observed_data\n\njulia> idata_cat3.posterior\n┌ 100×4×3×2 Dataset ┐\n├───────────────────┴───────────────────────────────────────── dims ┐\n  ↓ draw,\n  → chain,\n  ↗ a_dim Categorical{String} [\"x\", …, \"z\"] ForwardOrdered,\n  ⬔ run\n├─────────────────────────────────────────────────────────── layers ┤\n  :a eltype: Float64 dims: draw, chain, a_dim, run size: 100×4×3×2\n  :b eltype: Float64 dims: draw, chain, run size: 100×4×2\n├───────────────────────────────────────────────────────── metadata ┤\n  Dict{String, Any} with 1 entry:\n  \"created_at\" => \"2025-07-25T10:11:18.92\"\n\njulia> idata_cat3.observed_data\n┌ 10-element Dataset ┐\n├────────────────────┴───────────────── dims ┐\n  ↓ y_dim_1\n├──────────────────────────────────── layers ┤\n  :y eltype: Float64 dims: y_dim_1 size: 10\n├────────────────────────────────────────────┴ metadata ┐\n  Dict{String, Any} with 1 entry:\n  \"created_at\" => \"2025-07-25T10:11:18.951\"\n\n\n\n\n\n","category":"function"},{"location":"inference_data/#Base.merge","page":"InferenceData","title":"Base.merge","text":"merge(data::InferenceData...) -> InferenceData\n\nMerge InferenceData objects.\n\nThe result contains all groups in data and others. If a group appears more than once, the one that occurs last is kept.\n\nSee also: cat\n\nExamples\n\nHere we merge an InferenceData containing only a posterior group with one containing only a prior group to create a new one containing both groups.\n\njulia> idata1 = from_dict(Dict(:a => randn(100, 4, 3), :b => randn(100, 4)))\nInferenceData with groups:\n  > posterior\n\njulia> idata2 = from_dict(; prior=Dict(:a => randn(100, 1, 3), :c => randn(100, 1)))\nInferenceData with groups:\n  > prior\n\njulia> idata_merged = merge(idata1, idata2)\nInferenceData with groups:\n  > posterior\n  > prior\n\n\n\n\n\n","category":"function"},{"location":"inference_data/#I/O-extensions","page":"InferenceData","title":"I/O extensions","text":"","category":"section"},{"location":"inference_data/","page":"InferenceData","title":"InferenceData","text":"The following types of storage are provided via extensions.","category":"page"},{"location":"inference_data/#NetCDF-I/O-using-NCDatasets.jl","page":"InferenceData","title":"NetCDF I/O using NCDatasets.jl","text":"","category":"section"},{"location":"inference_data/#InferenceObjects.from_netcdf","page":"InferenceData","title":"InferenceObjects.from_netcdf","text":"from_netcdf(path::AbstractString; kwargs...) -> InferenceData\n\nLoad an InferenceData from an unopened NetCDF file.\n\nRemaining kwargs are passed to NCDatasets.NCDataset. This method loads data eagerly. To instead load data lazily, pass an opened NCDataset to from_netcdf.\n\nnote: Note\nThis method requires that NCDatasets is loaded before it can be used.\n\nExamples\n\njulia> using InferenceObjects, NCDatasets\n\njulia> idata = from_netcdf(\"centered_eight.nc\")\nInferenceData with groups:\n  > posterior\n  > posterior_predictive\n  > sample_stats\n  > prior\n  > observed_data\n\nfrom_netcdf(ds::NCDatasets.NCDataset; load_mode) -> InferenceData\n\nLoad an InferenceData from an opened NetCDF file.\n\nload_mode defaults to :lazy, which avoids reading variables into memory. Operations on these arrays will be slow. load_mode can also be :eager, which copies all variables into memory. It is then safe to close ds. If load_mode is :lazy and ds is closed after constructing InferenceData, using the variable arrays will have undefined behavior.\n\nExamples\n\nHere is how we might load an InferenceData from an InferenceData lazily from a web-hosted NetCDF file.\n\njulia> using HTTP, InferenceObjects, NCDatasets\n\njulia> resp = HTTP.get(\"https://github.com/arviz-devs/arviz_example_data/blob/main/data/centered_eight.nc?raw=true\");\n\njulia> ds = NCDataset(\"centered_eight\", \"r\"; memory = resp.body);\n\njulia> idata = from_netcdf(ds)\nInferenceData with groups:\n  > posterior\n  > posterior_predictive\n  > sample_stats\n  > prior\n  > observed_data\n\njulia> idata_copy = copy(idata); # disconnect from the loaded dataset\n\njulia> close(ds);\n\n\n\n\n\n","category":"function"},{"location":"inference_data/#InferenceObjects.to_netcdf","page":"InferenceData","title":"InferenceObjects.to_netcdf","text":"to_netcdf(data, dest::AbstractString; group::Symbol=:posterior, kwargs...)\nto_netcdf(data, dest::NCDatasets.NCDataset; group::Symbol=:posterior)\n\nWrite data to a NetCDF file.\n\ndata is any type that can be converted to an InferenceData using convert_to_inference_data. If not an InferenceData, then group specifies which group the data represents.\n\ndest specifies either the path to the NetCDF file or an opened NetCDF file. If dest is a path, remaining kwargs are passed to NCDatasets.NCDataset.\n\nnote: Note\nThis method requires that NCDatasets is loaded before it can be used.\n\nExamples\n\njulia> using InferenceObjects, NCDatasets\n\njulia> idata = from_namedtuple((; x = randn(4, 100, 3), z = randn(4, 100)))\nInferenceData with groups:\n  > posterior\n\njulia> to_netcdf(idata, \"data.nc\")\n\"data.nc\"\n\n\n\n\n\n","category":"function"},{"location":"extensions/posteriorstats/#Extension-of-PosteriorStats","page":"PosteriorStats","title":"Extension of PosteriorStats","text":"","category":"section"},{"location":"extensions/posteriorstats/","page":"PosteriorStats","title":"PosteriorStats","text":"The following methods of PosteriorStats.jl are extended by this package.","category":"page"},{"location":"extensions/posteriorstats/","page":"PosteriorStats","title":"PosteriorStats","text":"Modules = [\n    Base.get_extension(InferenceObjects, :InferenceObjectsPosteriorStatsExt),\n    PosteriorStats,\n    StatsBase,\n]","category":"page"},{"location":"extensions/posteriorstats/#PosteriorStats.eti-Tuple{InferenceData}","page":"PosteriorStats","title":"PosteriorStats.eti","text":"eti(data::InferenceData; kwargs...) -> Dataset\neti(data::Dataset; kwargs...) -> Dataset\n\nCalculate the equal-tailed interval (ETI) for each parameter in the data.\n\nFor more details and a description of the kwargs, see PosteriorStats.eti.\n\n\n\n\n\n","category":"method"},{"location":"extensions/posteriorstats/#PosteriorStats.hdi-Tuple{InferenceData}","page":"PosteriorStats","title":"PosteriorStats.hdi","text":"hdi(data::InferenceData; kwargs...) -> Dataset\nhdi(data::Dataset; kwargs...) -> Dataset\n\nCalculate the highest density interval (HDI) for each parameter in the data.\n\nFor more details and a description of the kwargs, see PosteriorStats.hdi.\n\n\n\n\n\n","category":"method"},{"location":"extensions/posteriorstats/#PosteriorStats.loo-Tuple{Union{Dataset, InferenceData}}","page":"PosteriorStats","title":"PosteriorStats.loo","text":"loo(data::Dataset; [var_name::Symbol,] kwargs...) -> PSISLOOResult{<:NamedTuple,<:Dataset}\nloo(data::InferenceData; [var_name::Symbol,] kwargs...) -> PSISLOOResult{<:NamedTuple,<:Dataset}\n\nCompute PSIS-LOO from log-likelihood values in data.\n\nIf more than one log-likelihood variable is present, then var_name must be provided.\n\nFor more details and a description of the kwargs, see PosteriorStats.loo.\n\nExamples\n\nCalculate PSIS-LOO of a model:\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> loo(idata)\nPSISLOOResult with estimates\n elpd  se_elpd    p  se_p\n  -31      1.4  0.9  0.33\n\nand PSISResult with 500 draws, 4 chains, and 8 parameters\nPareto shape (k) diagnostic values:\n                    Count      Min. ESS\n (-Inf, 0.5]  good  4 (50.0%)  270\n  (0.5, 0.7]  okay  4 (50.0%)  307\n\n\n\n\n\n","category":"method"},{"location":"extensions/posteriorstats/#PosteriorStats.loo_pit-Tuple{InferenceData, AbstractArray}","page":"PosteriorStats","title":"PosteriorStats.loo_pit","text":"loo_pit(idata::InferenceData, log_weights; kwargs...) -> DimArray\n\nCompute LOO-PIT values using existing normalized log LOO importance weights.\n\nKeywords\n\ny_name: Name of observed data variable in idata.observed_data. If not provided, then the only observed data variable is used.\ny_pred_name: Name of posterior predictive variable in idata.posterior_predictive. If not provided, then y_name is used.\nkwargs: Remaining keywords are forwarded to the base method PosteriorStats.loo_pit.\n\nSee PosteriorStats.loo_pit for more details.\n\nExamples\n\nCalculate LOO-PIT values using already computed log weights.\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> loo_result = loo(idata; var_name=:obs);\n\njulia> loo_pit(idata, loo_result.psis_result.log_weights; y_name=:obs)\n┌ 8-element DimArray{Float64, 1} loo_pit_obs ┐\n├────────────────────────────────────────────┴─────────────────── dims ┐\n  ↓ school Categorical{String} [\"Choate\", …, \"Mt. Hermon\"] Unordered\n└──────────────────────────────────────────────────────────────────────┘\n \"Choate\"            0.942759\n \"Deerfield\"         0.641057\n \"Phillips Andover\"  0.32729\n \"Phillips Exeter\"   0.581451\n \"Hotchkiss\"         0.288523\n \"Lawrenceville\"     0.393741\n \"St. Paul's\"        0.886175\n \"Mt. Hermon\"        0.638821\n\n\n\n\n\n","category":"method"},{"location":"extensions/posteriorstats/#PosteriorStats.loo_pit-Tuple{InferenceData}","page":"PosteriorStats","title":"PosteriorStats.loo_pit","text":"loo_pit(idata::InferenceData; kwargs...) -> DimArray\n\nCompute LOO-PIT from groups in idata using PSIS-LOO.\n\nKeywords\n\ny_name: Name of observed data variable in idata.observed_data. If not provided, then the only observed data variable is used.\ny_pred_name: Name of posterior predictive variable in idata.posterior_predictive. If not provided, then y_name is used.\nlog_likelihood_name: Name of log-likelihood variable in idata.log_likelihood. If not provided, then y_name is used if idata has a log_likelihood group, otherwise the only variable is used.\nreff::Union{Real,AbstractArray{<:Real}}: The relative effective sample size(s) of the likelihood values. If an array, it must have the same data dimensions as the corresponding log-likelihood variable. If not provided, then this is estimated using ess.\nkwargs: Remaining keywords are forwarded to PosteriorStats.loo_pit.\n\nSee PosteriorStats.loo_pit for more details.\n\nExamples\n\nCalculate LOO-PIT values using as test quantity the observed values themselves.\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> loo_pit(idata; y_name=:obs)\n┌ 8-element DimArray{Float64, 1} loo_pit_obs ┐\n├────────────────────────────────────────────┴─────────────────── dims ┐\n  ↓ school Categorical{String} [\"Choate\", …, \"Mt. Hermon\"] Unordered\n└──────────────────────────────────────────────────────────────────────┘\n \"Choate\"            0.942759\n \"Deerfield\"         0.641057\n \"Phillips Andover\"  0.32729\n \"Phillips Exeter\"   0.581451\n \"Hotchkiss\"         0.288523\n \"Lawrenceville\"     0.393741\n \"St. Paul's\"        0.886175\n \"Mt. Hermon\"        0.638821\n\n\n\n\n\n","category":"method"},{"location":"extensions/posteriorstats/#PosteriorStats.r2_score-Tuple{InferenceData}","page":"PosteriorStats","title":"PosteriorStats.r2_score","text":"r2_score(idata::InferenceData; y_name, y_pred_name) -> (; r2, r2_std)\n\nCompute R² from idata, automatically formatting the predictions to the correct shape.\n\nKeywords\n\ny_name: Name of observed data variable in idata.observed_data. If not provided, then the only observed data variable is used.\ny_pred_name: Name of posterior predictive variable in idata.posterior_predictive. If not provided, then y_name is used.\n\nSee PosteriorStats.r2_score for more details.\n\nExamples\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"regression10d\");\n\njulia> r2_score(idata) |> pairs\npairs(::NamedTuple) with 2 entries:\n  :r2     => 0.998385\n  :r2_std => 0.000100621\n\n\n\n\n\n","category":"method"},{"location":"extensions/posteriorstats/#PosteriorStats.summarize-Tuple{InferenceData, Vararg{Any}}","page":"PosteriorStats","title":"PosteriorStats.summarize","text":"summarize(data::InferenceData, stats_funs...; group=:posterior, kwargs...)\nsummarize(data::Dataset, stats_funs...; kwargs...)\n\nCompute summary statistics for the data using the provided functions.\n\nFor verbose variable labels, provide compact_labels=false. For details on stats_funs and kwargs, see PosteriorStats.summarize.\n\nExamples\n\nCompute all default summary statistics for the eight schools model in the centered parameterization:\n\njulia> using ArviZExampleData, PosteriorStats, StatsBase\n\njulia> data = load_example_data(\"centered_eight\");\n\njulia> summarize(data)\nSummaryStats\n                          mean  std  eti94          ess_tail  ess_bulk  rhat  mcse_mean  mcse_std\n mu                        4.2  3.3  -2.11 .. 9.90       622       241  1.03       0.21     0.088\n theta[Choate]             6.4  5.9  -3.05 .. 19.1       937       572  1.01       0.25     0.20\n theta[Deerfield]          5.0  4.9  -4.49 .. 14.2      1214       532  1.01       0.21     0.15\n theta[Phillips Andover]   3.4  5.4  -8.17 .. 12.7      1017       511  1.01       0.23     0.17\n theta[Phillips Exeter]    4.8  5.2  -4.84 .. 14.5       911       572  1.01       0.21     0.21\n theta[Hotchkiss]          3.5  4.8  -6.11 .. 12.0       789       347  1.02       0.25     0.15\n theta[Lawrenceville]      3.7  5.2  -6.62 .. 12.6       957       506  1.01       0.22     0.21\n theta[St. Paul's]         6.5  5.2  -2.38 .. 18.3      1031       528  1.01       0.22     0.15\n theta[Mt. Hermon]         4.8  5.7  -5.52 .. 16.0      1045       538  1.01       0.24     0.23\n tau                       4.3  3.0   1.06 .. 11.5       214       128  1.03       0.22     0.14\n\nCompute the mean, standard deviation, median, and median absolute deviation of the theta parameters:\n\njulia> summarize(data.posterior[(:theta,)], (:mean, :std) => mean_and_std, median, mad)\nSummaryStats\n                          mean   std  median   mad\n theta[Choate]            6.42  5.85    5.80  4.95\n theta[Deerfield]         4.95  4.91    5.02  4.68\n theta[Phillips Andover]  3.42  5.43    3.74  4.84\n theta[Phillips Exeter]   4.75  5.25    4.69  4.84\n theta[Hotchkiss]         3.45  4.78    3.62  4.55\n theta[Lawrenceville]     3.66  5.23    3.90  4.88\n theta[St. Paul's]        6.51  5.24    6.09  4.57\n theta[Mt. Hermon]        4.82  5.70    4.65  4.89\n\n\n\n\n\n","category":"method"},{"location":"extensions/posteriorstats/#PosteriorStats.waic-Tuple{Union{Dataset, InferenceData}}","page":"PosteriorStats","title":"PosteriorStats.waic","text":"waic(data::Dataset; [var_name::Symbol]) -> WAICResult{<:NamedTuple,<:Dataset}\nwaic(data::InferenceData; [var_name::Symbol]) -> WAICResult{<:NamedTuple,<:Dataset}\n\nCompute WAIC from log-likelihood values in data.\n\nIf more than one log-likelihood variable is present, then var_name must be provided.\n\nSee PosteriorStats.waic for more details.\n\nExamples\n\nCalculate WAIC of a model:\n\njulia> using ArviZExampleData, PosteriorStats\n\njulia> idata = load_example_data(\"centered_eight\");\n\njulia> waic(idata)\nWAICResult with estimates\n elpd  se_elpd    p  se_p\n  -31      1.4  0.9  0.32\n\n\n\n\n\n","category":"method"},{"location":"extensions/posteriorstats/#StatsBase.summarystats-Tuple{InferenceData}","page":"PosteriorStats","title":"StatsBase.summarystats","text":"summarystats(data::InferenceData; group=:posterior, kwargs...) -> SummaryStats\nsummarystats(data::Dataset; kwargs...) -> SummaryStats\n\nCompute default summary statistics for the data using PosteriorStats.summarize.\n\n\n\n\n\n","category":"method"},{"location":"#InferenceObjects","page":"Home","title":"InferenceObjects","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"InferenceObjects.jl is a Julia implementation of the InferenceData schema for storing results of Bayesian inference. Its purpose is to serve the following three goals:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Usefulness in the analysis of Bayesian inference results.\nReproducibility of Bayesian inference analysis.\nInteroperability between different inference backends and programming languages.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The implementation consists primarily of the InferenceData and Dataset structures. InferenceObjects also provides the function convert_to_inference_data, which may be overloaded by inference packages to define how various inference outputs can be converted to an InferenceData.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For examples of how InferenceData can be used, see the ArviZ.jl documentation.","category":"page"}]
}
